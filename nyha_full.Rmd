---
title: "Supplementary material for: Relationship Between Objective and Subjective Assessment of Functional Capacity in Patients with Chronic Heart Failure and its Dependence on Medication Adherence"
output: 
  bookdown::word_document2: 
    toc: false
    number_sections: false
    reference_docx: "output_template.docx"
date: "Version: `r format(Sys.time(), '%Y-%m-%d')`"
---

```{r setup, message=FALSE, echo = FALSE, results='hide', warning = FALSE}
library(tidyverse)
library(readxl)
library(brms)

knitr::opts_chunk$set(echo=FALSE, fig.width = 8)

options(mc.cores = 4, brms.backend = "cmdstanr", dplyr.summarise.inform = FALSE)
cache_dir <- here::here("stored_fits")
if(!dir.exists(cache_dir)) {
  dir.create(cache_dir)
}

document_output <- isTRUE(getOption('knitr.in.progress'))

if(document_output) {
  table_format <- function(x, caption = NULL, align = NULL) { 
    knitr::kable(x, caption = caption, align = align) 
  }
} else {
  table_format <- function(x, caption = NULL, align = NULL) { x }
}


theme_set(cowplot::theme_cowplot())

devtools::load_all()

source(here::here("data_into_session.R"))
data_wide <- data_wide %>% rename(Weber_spiro = NYHA_spiro_obj, NYHA_spiro = NYHA_spiro_subj, VO2_peak = VO2_max)
data_long <- data_long %>% rename(Weber_spiro = NYHA_spiro_obj, NYHA_spiro = NYHA_spiro_subj, VO2_peak = VO2_max)
```

```{r}
NYHA_VO2_peak_threshold = c(10, 16, 20)
NYHA_VO2_peak_breaks = c(min(data_wide$VO2_peak, na.rm = TRUE)-0.01, 10-1e-6, 16, 20+1e-6, max(data_wide$VO2_peak, na.rm = TRUE) + 0.1)
data_wide <- data_wide %>% 
  mutate(Weber_spiro_manual = Weber_spiro,
         Weber_spiro = VO2_peak %>% cut(NYHA_VO2_peak_breaks, labels = 4:1, right = FALSE) %>% as.character() %>% as.integer())

# Subjects 113 and 41 have verified mismatch, where calculated value should be preferred
mismatched_NYHA <- data_wide %>% filter((Weber_spiro_manual != Weber_spiro & !is.na(Weber_spiro)) | 
                       is.na(Weber_spiro) & !is.na(Weber_spiro),
                       !(subject_id %in% c(113, 41)))  %>% 
  select(subject_id, cohort, Weber_spiro, Weber_spiro_manual, VO2_peak)

if(nrow(mismatched_NYHA) > 0) {
  stop("Mismatched NYHA")
}

data_long_sum_no_fur <- data_long %>%
  filter(has) %>%
  group_by(subject_id, cohort) %>%
  summarise(N_adherent = sum(has & adherent_int, na.rm = TRUE), N_drugs = sum(has, na.rm = TRUE),
            N_adherent_no_fur = sum(has & adherent_int & drug_class != "furosemide", na.rm = TRUE), 
            N_drugs_no_fur = sum(has  & drug_class != "furosemide", na.rm = TRUE),
            # adherence_category = case_when(N_adherent == N_drugs ~ "C - all",
            #                      N_drugs > 1 & N_adherent == N_drugs_no_fur - 1 ~ "B - all but one",
            #                      TRUE ~ "A - nonadherent"
            #                      ),
            adherence_category = case_when(N_adherent_no_fur == N_drugs_no_fur ~ "Fully adherent",
                                 TRUE ~ "Nonadherent"
                                 ),
            adherence_category = factor(adherence_category, 
                                        levels = c("Nonadherent", "Fully adherent"))  )

data_wide_old <- data_wide 
data_wide <- data_wide %>% 
  inner_join(data_long_sum_no_fur, by = c("subject_id", "cohort"))

if(nrow(data_wide) != nrow(data_wide_old)) {
  stop("Bad join")
}

data_nyha <- data_wide %>% filter(!is.na(NYHA_spiro), !is.na(VO2_peak))
```


```{r}
# One subject has two different NYHA values from supposedly the same measurement.
# Check:
# data_nyha %>% group_by(subject_id) %>% filter(n() > 1, length(unique(spiro_date)) == 1, length(unique(NYHA_spiro)) != 1) %>% select(subject_id, VO2_peak, NYHA_spiro, spiro_date) %>%
#  arrange(subject_id) %>% table_format()
```


```{r}
# Remove duplicates
data_nyha <- data_nyha %>% 
  ungroup() %>%
  group_by(subject_id) %>% 
  filter(n() == 1 | length(unique(spiro_date)) == 2 | cohort == 2018) %>%
  ungroup()
```


## Definitions & summaries

VO~2~ peak is converted to Weber via the following table:

```{r}
data.frame( 
           `VO~2~ peak [ml/kg/min]` = c(
             paste0("< ", NYHA_VO2_peak_threshold[1]),
             paste0(NYHA_VO2_peak_threshold[1], " - ", NYHA_VO2_peak_threshold[2]),
             paste0(NYHA_VO2_peak_threshold[2], " - ", NYHA_VO2_peak_threshold[3]),
             paste0("> ", NYHA_VO2_peak_threshold[3])
           ), `Weber class` = LETTERS[4:1], check.names = FALSE)  %>% 
  table_format()
```


We use 2 categories of adherence:

- "all", when adherent to all drugs prescribed that can be measured
- "nonadherent" otherwise

In both cases, we don't take into account adherence to furosemide.

```{r}
sum_percent <- function(x) {
  paste0(sum(x, na.rm = TRUE), " (", scales::percent(mean(x, na.rm = TRUE), accuracy = 1), ")")
}

mean_iqr <- function(x) {
  paste0(round(mean(x, na.rm = TRUE)), " (", round(quantile(x, 0.25, na.rm = TRUE)), " - ", round(quantile(x, 0.75, na.rm = TRUE)), ")")
}

data_groups <- rbind(data_nyha %>% mutate(adherence_category = "All"), data_nyha) %>%
  mutate(adherence_category = factor(adherence_category, levels = c("All", levels(data_nyha$adherence_category)))) %>%
  group_by(adherence_category) 

data_groups %>%
  summarise(`N measurements` = n(),
            `N subjects measured twice` = n() - length(unique(subject_id)), 
            Male =  sum_percent(sex == "M"),
            `Age (mean, IQR)` = mean_iqr(age),
            `Diabetes` = sum_percent(diabetes == 1),
            `EF (mean, IQR)` = mean_iqr(EF_numeric),
            `NT-proBNP [pg/ml] (mean, IQR)` = mean_iqr(lab_NT_proBNP),
            `Diagnosis - iKMP only` = sum_percent(diagnosis_group == "iKMP"),
            `Diagnosis - dKMP only` = sum_percent(diagnosis_group == "dKMP"),
            `Diagnosis - iKMP and dKMP` = sum_percent(diagnosis_group == "iKMP_dKMP"),
            `Diagnosis - Other` = sum_percent(diagnosis_group == "Other")
            
            
) %>%
  column_to_rownames("adherence_category") %>% t() %>%
  as.data.frame() %>% table_format(caption = "Summary of the characteristics of the patients enrolled, grouped by adherence category.") 
```

The "Other" diagnosis includes:

```{r}
data_nyha %>% filter(diagnosis_group == "Other") %>% select(diagnosis) %>% table_format()
```

The number of patients per Weber class:

```{r}
t_nyha_obj <- table(data_nyha$Weber_spiro)
if(any(is.na(data_nyha$Weber_spiro))) {
  stop("Unhandled NA")
}
tibble(`Weber` = LETTERS[1:4], N = as.numeric(t_nyha_obj), `%` = paste0("(", scales::percent(as.numeric(t_nyha_obj) / nrow(data_nyha), accuracy = 1), ")")) %>% table_format()

```

The number of patients per NYHA class:

```{r}
t_nyha_subj <- table(data_nyha$NYHA_spiro)
if(any(is.na(data_nyha$NYHA_spiro))) {
  stop("Unhandled NA")
}
tibble(`NYHA` = paste0("NYHA ", names(t_nyha_subj)), N = as.numeric(t_nyha_subj), `%` = paste0("(", scales::percent(as.numeric(t_nyha_subj) / nrow(data_nyha), accuracy = 1), ")")) %>% table_format()
```

Mean VO~2~ peak per NYHA class

```{r}
data_nyha %>% group_by(NYHA_spiro) %>%
  summarise(N = n(), `Mean VO~2~ peak` = mean(VO2_peak), `SD VO~2~ peak` = sd(VO2_peak)) %>% 
  rename(NYHA = NYHA_spiro) %>%
  table_format()
```


```{r}
data_groups %>%
  summarise(`N measurements` = n(),
            `Prescribed furosemide` = sum_percent(has.furosemide == 1),
            `Furosemide measured (of those prescribed)` = sum_percent(replace_na(adherent.furosemide[has.furosemide == 1] != 0, FALSE)),
            `Adherent to furosemide (of those measured)` = sum_percent(adherent.furosemide[has.furosemide == 1 & adherent.furosemide != 0] == 1),
            `Prescribed ARNI` = sum_percent(has.ARNI == 1),
            `ARNI status unknown` = sum_percent(is.na(has.ARNI)),
            `Presribed BB` = sum_percent(has.BB == 1),
            `BB status unknown` = sum_percent(is.na(has.BB)),
            `Presribed ACEi` = sum_percent(has.ACEi == 1),
            `Acei status unknown` = sum_percent(is.na(has.ACEi)),
            `Prescribed sartan` = sum_percent(has.sartan == 1),
            `sartan status unknown` = sum_percent(is.na(has.sartan)),
            `Prescribed MRA` = sum_percent(has.MRA == 1),
            `MRA status unknown` = sum_percent(is.na(has.MRA)),
            `Prescribed CaB` = sum_percent(has.CaB == 1),
            `CaB status unknown` = sum_percent(is.na(has.CaB)),
            `Prescribed statin` = sum_percent(has.statin == 1),
            `Statin status unknown` = sum_percent(is.na(has.statin)),
            `Prescribed alpha blocker` = sum_percent(has.alpha_blocker == 1),
            `Alpha blocker status unknown` = sum_percent(is.na(has.alpha_blocker)),
            `Prescribed digoxin` = sum_percent(has.digoxin == 1),
            `Digoxin status unknown` = sum_percent(is.na(has.digoxin)),

) %>%
  column_to_rownames("adherence_category") %>% t() %>%
  as.data.frame() %>% table_format(caption = "Summary of the drugs taken by the patients enrolled, grouped by adherence category.") 
```

We see that vast majority of patients was fully adherent (if we ignore furosemide, which has generally low adherence, but is not expected to be taken continuously).

```{r}
# data_nyha %>% filter(!grepl("ikmp", diagnosis, ignore.case = TRUE), !grepl("dkmp", diagnosis, ignore.case = TRUE)) %>%
#   pull(diagnosis)
```


## Visualising the data

```{r, fig.cap="Weber - as determined by VO~2~ peak against NYHA. Each dot is a patient. Highlihted regions suggest compatibility between the NYHA and Weber class. Position of the dots within each region is random."}
brewer_palette_adherence <- "Set1"
scale_color_adherence <- scale_color_brewer("Adherence", palette = brewer_palette_adherence)
scale_fill_adherence <- scale_fill_brewer("Adherence", palette = brewer_palette_adherence)

jitter_size <- 0.3
exp_limits <- c(1 - jitter_size - 0.1, 4 + jitter_size + 0.1)
valid_tiles <- tribble(~Weber_spiro, ~NYHA_spiro,
                       1, "1",
                       1, "1-2",
                       2, "1-2",
                       2, "2",
                       2, "2-3",
                       3, "2-3",
                       3, "3",
                       3, "3-4",
                       4, "3-4",
                       4, "4") %>%
  mutate(NYHA_spiro = factor(NYHA_spiro, levels = levels(data_nyha$NYHA_spiro)))
         
plot_scatter <-  data_nyha %>%
  ggplot(aes(y = as.integer(NYHA_spiro), x = Weber_spiro, color = adherence_category, fill = adherence_category,
             shape = adherence_category, group = adherence_category)) + 
  #geom_abline(slope = 2, intercept = -1) +
  #geom_smooth(formula = y ~ x, method = "lm", alpha = 0.15) + 
  geom_tile(data = valid_tiles, aes(y = as.integer(NYHA_spiro), x = Weber_spiro), inherit.aes = FALSE, fill = "orangered", alpha = 0.2) +
  geom_jitter(width = jitter_size, height = jitter_size, size = 1, alpha = 0.7) +
  scale_x_continuous(expression(paste("Weber from ", VO[2], " peak")), minor_breaks = 2:4 - 0.5, breaks = 1:4, labels = LETTERS[1:4]) +
  scale_y_continuous("NYHA", minor_breaks = 2:7 - 0.5, breaks = 1:7, labels = levels(data_nyha$NYHA_spiro)) +
  scale_color_adherence +
  scale_fill_adherence +
  scale_shape_discrete("Adherence") +
  #expand_limits(x = exp_limits, y = exp_limits) +
  #coord_cartesian(ylim = c(1 - jitter_size - 0.1, 7 + jitter_size + 0.1)) +
  theme(panel.grid.minor = element_line(colour = "lightgray"))

plot_scatter
```




```{r, fig.cap = "Weber - as determined by VO~2~ peak (horizontal) against NYHA (vertical). Each subplot shows the counts of various adherence categories for the given combination of Weber and NYHA. Highlihted subplots suggest compatibility between the NYHA and Weber class."}
plot_bars <- data_nyha %>% 
  ggplot(aes(x = adherence_category, fill = adherence_category, color = adherence_category)) +
  geom_tile(data = valid_tiles, aes(x = "Fully adherent", y = 10, width = 3, height = 22), inherit.aes = FALSE, fill = "orangered", alpha = 0.2) +
  stat_count() + facet_grid(NYHA_spiro~LETTERS[Weber_spiro]) + scale_color_adherence + scale_fill_adherence + scale_y_continuous("Count", breaks = c(0, 20)) + 
  scale_x_discrete("", limits = c("Nonadherent", "Fully adherent")) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

plot_bars

```

In both variants of the plots we see that there is substantial number of patients for whom the NYHA and Weber are discordant. But substantially more frequently we see the "objective" Weber based on VO~2~ peak to be higher than NYHA. In the extreme a single patient considered subjectively as NYHA 1 had Weber D.


```{r}
data_nyha %>% 
  rowwise() %>%
  mutate(`NYHA vs. Weber status` = 
           case_when(grepl(Weber_spiro, as.character(NYHA_spiro)) ~ "Concordant",
                     Weber_spiro < as.integer(substr(NYHA_spiro, 1, 1)) ~ "Weber lower",
                     Weber_spiro > as.integer(substr(NYHA_spiro, 1, 1)) ~ "Weber higher",
                     TRUE ~ "Invalid")) %>%
  # filter(`NYHA status` == "Objective higher") %>%
  # select(Weber_spiro, NYHA_spiro)
  
  group_by(`NYHA vs. Weber status`) %>% tally() %>%
  table_format(caption = "Count of patients based on difference between NYHA and Weber based on VO~2~ peak")
                                               
```





```{r, fig.cap="NYHA class compared to VO~2~ peak. Each dot is a patient.The thick light blue line shows expected output if Weber based on VO~2~ peak exactly corresponded with NYHA. Lines show linear trends fitted per each adherence category and the associated 95% confidence interval."}
step_data <- tibble(VO2_peak = NYHA_VO2_peak_breaks, NYHA = factor(as.character(c(4:1,1)), levels = levels(data_nyha$NYHA_spiro)))
                    
theoretical_geom <- geom_step(aes(x = VO2_peak, y = as.integer(NYHA)), data = step_data, inherit.aes = FALSE, color = "lightblue", size = 2)

#scale_x_VO2 <- scale_x_continuous("VO2 peak [ml/kg/min]", minor_breaks = NYHA_VO2_peak_breaks)
vo2_label <- expression(paste(VO[2],  " peak [ml/kg/min]"))
scale_x_VO2 <- scale_x_continuous(vo2_label, minor_breaks = NYHA_VO2_peak_breaks)

plot_VO2_peak <- data_nyha %>%
  ggplot(aes(y = as.integer(NYHA_spiro), x = VO2_peak, color = adherence_category, fill=adherence_category)) + 
  theoretical_geom +
  geom_smooth(method = lm, formula = y ~ x, alpha = 0.15) +
  geom_jitter(width = 0, height = 0.1, alpha = 0.7) +
  scale_y_continuous("NYHA", minor_breaks = 2:7 - 0.5, breaks = 1:7, labels = levels(data_nyha$NYHA_spiro)) +
  scale_color_adherence +
  scale_fill_adherence +
  scale_x_VO2 +
  theme(panel.grid.minor.x = element_line(colour = "lightgray"))

plot_VO2_peak
```

```{r}
n_low_VO2_4 <- data_nyha %>% filter(VO2_peak <= 10, NYHA_spiro >= "3-4") %>% nrow()
```


Importantly, despite seeing a large number of patients with VO~2~ peak < 10, only `r n_low_VO2_4` of those patients have NYHA 3-4 or 4. So it is clear that in that region, there is a major discrepancy between the two assessments.

Additionally we see that the range of VO~2~ peak values for NYHA 1 up to NYHA 2 is almost identical. 


```{r, fig.cap = "Change in NYHA and VO~2~ peak for patients measured twice. Each arrow represents a single patient, it starts at the location corresponding to the first measurement and ends in the second measurement."}
repeated_measurements <- data_nyha %>% group_by(subject_id) %>% filter(n() > 1)

# repeated_measurements %>% select(subject_id, cohort, VO2_peak, NYHA_spiro) %>%
#   rename(NYHA_subj = NYHA_spiro) %>%
#   pivot_wider(names_from = "cohort", values_from = c("VO2_peak", "NYHA_subj"))
  #summarise(VO2_peak_1 = VO2_peak[cohort == 2018], VO2_peak_2 =  change_VO)

repeated_measurements %>% arrange(subject_id, cohort) %>%
  ggplot(aes(x = VO2_peak, y = as.integer(NYHA_spiro), group = subject_id)) +
  theoretical_geom +
  #geom_point(size = 2) + 
  geom_path(arrow = arrow(length=unit(0.30,"cm"), type = "closed")) +
  scale_y_continuous("NYHA", minor_breaks = 2:7 - 0.5, breaks = 1:7, labels = levels(data_nyha$NYHA_spiro))  +
  scale_x_continuous(vo2_label)

```

A small number of patients (`r length(unique(repeated_measurements$subject_id))`) was measured
by spiroergometry twice. While most of the patients follow an expected trajectory of diesease progression (lower VO~2~ peak and higher NYHA class at later measurement), we can also see patients that have improved their 
 NYHA class, in one case even despite a noticeable decrease in VO~2~ peak.

## Thresholds used by clinicians

We can try to find thresholds on VO~2~ peak that would mimic clinicians decisions in NYHA the best.
To achieve that we use a cumulative ordinal model with a logit link. Briefly, the model assumes that the NYHA classification arises by a clinician noisily observing a quantity proportional to VO~2~ peak and then putting thresholds on this noisy observation. For mathematical convenience we use the logarithm of VO~2~ peak (the results are however very similar when using VO~2~ peak directly).



We use a model including the "transitional" NYHA classes and thresholds corresponding to all of those are estimated. In the summary below we however do not show thresholds for NYHA 4 as it is almost 0 (once again, because only a single patient was classified as  NYHA 4).

```{r}
fit_boundaries_log <- brm(NYHA_spiro ~ log(VO2_peak), family = cumulative("logit"), data = data_nyha, 
                          iter = 6000, warmup = 2000,
                          file = here::here("stored_fits","boundaries_full_log"), file_refit = "on_change")
```


```{r, fig.height=3, fig.cap="Posterior distribution of thresholds in the model. The thresholds correspond to lower bounds, i.e. the NYHA 1 threshold means that VO~2~ peak above that threshold should be considered NYHA 1. Vertical dashed bars represent the commonly used thresholds."}

NYHA_colors <- c('#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00')
names(NYHA_colors) <- paste0("NYHA ", levels(data_nyha$NYHA_spiro)[1:5])
scale_color_nyha <- scale_color_manual(values = NYHA_colors)
scale_fill_nyha <- scale_fill_manual(values = NYHA_colors)


params <-  prepare_predictions(fit_boundaries_log)
b <- params$dpars$mu$fe$b[,1]
threshold_raw <- params$thres$thres
use_levels <- 5
threshold_samples <- array(-Inf, c(params$ndraws, use_levels))
for(i in 1:use_levels) {
  threshold_samples[,i] <- exp(threshold_raw[,i] / b)
}
threshold_samples[threshold_samples < -25] <- -25
colnames(threshold_samples) <- paste0("NYHA ", levels(data_nyha$NYHA_spiro)[1:use_levels])

predicted_thresholds <- as_tibble(threshold_samples) %>% mutate(sample = 1:n()) %>% pivot_longer(starts_with("NYHA"), names_to = "NYHA", values_to = "min_VO2_peak")

true_thresholds <- tibble(NYHA = paste0("NYHA ",3:1), min_VO2_peak = NYHA_VO2_peak_threshold)


predicted_thresholds %>%
  ggplot(aes(x = min_VO2_peak, color = NYHA, fill = NYHA)) + 
  geom_vline(aes(xintercept = min_VO2_peak, color = NYHA), size = 2, linetype = "dashed", data = true_thresholds) +
  geom_density(alpha = 0.5) + expand_limits(y = 0.9) +
  scale_y_continuous("Density") +
  scale_x_continuous(expression(paste("Min. ", VO[2]," peak"))) +
  scale_color_nyha +
  scale_fill_nyha


full_threshold_samples_summary <- 
  posterior::as_draws_matrix(threshold_samples) %>%
  posterior::summarise_draws(mean, ~ quantile(.x, probs = c(0.025,0.975))) %>%
  transmute(Threshold = variable, Mean = round(mean, 1), `95% CI` = paste0(round(`2.5%`,1), " - ", round(`97.5%`, 1)))

```

```{r}
full_threshold_samples_summary %>% table_format(caption = "Summary of the thresholds for NYHA classes based on the  model fit.") 
```

The comparison with the commonly used thresholds is not completely direct as it is not clear how should the transitional NYHA classes compare. Still some qualitative inferences can be made: patients have predominantly pure NYHA 1 classification only a bit above the Weber threshold of 20, but if some patients classified as  NYHA 1-2 were considered part of NYHA 1, the threshold of 20 wouldn't be completely unreasonable.  However, for NYHA 2, there is a substantial deviation from the Weber thresholds which increases for the NYHA 3 thresholds --- to better match the  measurements in our data, both thresholds would need to be revised downwards. We can't say anything conclusive about threshold for NYHA 4 due to the low number of patients with very high NYHA in our sample.



```{r}
boundaries_R2 <- suppressWarnings(bayes_R2(fit_boundaries_log))

```

Additionally, while adjusting the thresholds would remove systematic differences between  NYHA and Weber class based on spiroergometry, there is also substantial non-systematic variability between  NYHA levels of patients with the same VO~2~ peak measurements. Informally, one can see this by looking at patients with roughly the same VO~2~ peak - below is a figure showing the most populated range of VO~2~ peak values in the data:

```{r}
VO2_peak_example_low <- 13
VO2_peak_example_high <- 14

```

```{r, fig.cap=paste0("Distribution of  NYHA levels across patients with VO~2~ peak between ", VO2_peak_example_low, " and ", VO2_peak_example_high, ".")}
data_nyha %>% filter(VO2_peak >= VO2_peak_example_low & VO2_peak <= VO2_peak_example_high) %>%
  group_by(NYHA_spiro) %>% summarise(count = n()) %>%
  ggplot(aes(x = NYHA_spiro, y = count)) + geom_bar(stat = "identity")  +
  scale_x_discrete("NYHA")
  
  
#    %>% column_to_rownames("NYHA_spiro") %>% as.matrix() %>% t()
# 
# counts_VO2_peak_example <- counts_VO2_peak_example[1,]
```

Although NYHA class 2 is the most prominent, we see some representation from the full range of  NYHA classes.

One way to quantify this in a single number is to note that in our whole data, VO~2~ peak can explain between `r scales::percent(boundaries_R2[,"Q2.5"])` and `rscales::percent(boundaries_R2[,"Q97.5"])` of total variance in the outcome (approximate Bayesian $R^2$, 95% credible interval).

We can integrate those two views in one somewhat complex plot below:

```{r}
# predicted_thresholds %>% filter(sample %in% sample.int(n = 6000, size = 100)) %>%
#   ggplot(aes( x = min_VO2_peak, y = NYHA)) + ggdist::stat_interval(color = "black", aes(color_ramp = stat(level)), interval_size = 10) + scale_color_nyha
```


```{r, fig.cap = "Observed NYHA and VO~2~ peak measurements and model-derived thresholds. Each dot is a patient. The thick light blue line shows expected output if Weber based on the traditional conversion from VO~2~ peak exactly corresponded with  NYHA. Each thin black line corresponds to a single posterior sample of thresholds from the model, i.e. the cloud of lines shows our uncertainty about the best matching thresholds. "}
set.seed(45468855)
base <- predicted_thresholds %>% filter(sample %in% sample.int(n = 6000, size = 200)) %>%
  mutate(NYHA = as.numeric(factor(gsub("NYHA ", "", NYHA), levels = levels(data_nyha$NYHA_spiro))),
         shift = runif(max(sample), min = -0.1, max = 0.1)[sample]) # Draw the same shift per sample
base2 <- base %>% mutate(NYHA = NYHA + 1)

rbind(base2, base) %>%
  mutate(shift = if_else(NYHA == 1 | NYHA == 6, 0, shift)) %>%
  ggplot(aes( x = min_VO2_peak, y = NYHA, group = sample)) + geom_line(alpha = 0.1) +
  theoretical_geom +
  geom_jitter(data = data_nyha, aes(x = VO2_peak, y = as.integer(NYHA_spiro)), inherit.aes = FALSE,
              width = 0, height = 0.1, alpha = 0.8, color = "orangered" ) +
  scale_y_continuous("NYHA ", breaks = 1:7, labels = levels(data_nyha$NYHA_spiro)) +
  scale_x_VO2

  
```

A couple notes on the figure:

- generally we see the thresholds around the location where the number of patients that would be misclassified with higher NYHA is the same as number of patients misclassified with lower NYHA.
- the thresholds between NYHA 3-4 and NYHA 3 lies almost exlusively out of range of observed VO~2~ peak values. That's because even at VO~2~ peak < 8, majority of patients is classified as NYHA 3.
- the thresholds betweeen NYHA 1-2 and NYHA 1 are quite high and reach even beyond observed data. That's because there are generally few patients with VO~2~ peak above 25 and a lot of them have  NYHA 1-2 and one even has NYHA 2

This hopefully demonstrates both of the previously discussed points: 1) to avoid bias (systematic under/over estimation of NYHA), the thresholds would need to be moved and 2) even with the best thresholds, substantial proportion of patients would have discordant  NYHA and Weber based on VO~2~ peak.

## Association with adherence

We can then extend the cumulative ordinal model to also account for adherence groups. To make better use of the limited data, we assume the association should be monotonic, i.e. that the group "B - all but one" should lie somewhere between the two extreme groups.

```{r}
get_predictions <- function(fit, VO2_peak_vals, adherence = FALSE, ndraws = 6000) {
  data_to_predict <- tibble(VO2_peak = VO2_peak_vals)
  if(adherence) {
    data_to_predict <- data_to_predict %>% crossing(tibble(adherence_category = factor(c( "Nonadherent" , "Fully adherent"), ordered = TRUE, levels = levels(data_nyha$adherence_category) )))
  } 
  
  predictions <- posterior_epred(fit, ndraws = ndraws, newdata = data_to_predict, transform = TRUE, summary = FALSE)
  predictions_mean <- array(0, dim = dim(predictions)[1:2])
  ncategories <- dim(predictions)[3]
  if(ncategories != length(levels(fit$data$NYHA_spiro))) {
    stop("Mismatched ncategories")
  }
  for(i in 1:ncategories) {
    predictions_mean <- predictions_mean + i * predictions[,,i]
  }
  
  rownames(predictions_mean) <- paste0("V", 1:ndraws)
  predictions_df <- data_to_predict %>% cbind(as.data.frame(t(predictions_mean))) %>% 
    pivot_longer(all_of(rownames(predictions_mean)), names_to = "sample", values_to = "NYHA")  
  
  predictions_df
}

plot_fitted_trend <- function(fit, adherence = FALSE, ndraws = 100) {
  predictions_df <- get_predictions(fit, VO2_peak_vals = 5:40, adherence = adherence, ndraws = ndraws)
  ncategories <- length(levels(fit$data$NYHA_spiro))

  if(adherence) {
    predictions_df <- predictions_df %>% mutate(group = factor(paste(sample,adherence_category)))
    aesthetics <- aes(x = VO2_peak, y = NYHA, color = adherence_category)
  } else {
    predictions_df <- predictions_df %>% mutate(group = sample)
    aesthetics <- aes(x = VO2_peak, y = NYHA)
  }
  
  predictions_df %>% droplevels() %>%
    ggplot(aesthetics) +
    theoretical_geom +
    geom_line(aes(group = group), alpha = 0.3) + 
    scale_x_VO2 +
    scale_y_continuous("NYHA ", minor_breaks = 2:7 - 0.5, breaks = 1:7, labels = levels(data_nyha$NYHA_spiro)) +
    scale_color_adherence +
    expand_limits(y = ncategories) +
    theme(panel.grid.minor = element_line(colour = "lightgray")) +
    guides(color = guide_legend(override.aes = list(alpha = 1)))
}
```

We start by allowing a constant shift in the linear predictor (relative log-odds) based on adherence category.

```{r}
fit_adherence <- brm(NYHA_spiro ~ log(VO2_peak) + adherence_category, family = cumulative("logit"), data = data_nyha,
                     iter = 6000, warmup = 2000, refresh = 1500,
                     file = here::here("stored_fits","nyha_adherence"), file_refit = "on_change") 
```

```{r, fig.cap = "Summary of the constant shift model. Each line is a posterior sample showing association between VO~2~ peak and average  NYHA. The thick light blue line shows expected output if NYHA based on VO~2~ peak exactly corresponded with  NYHA."}
plot_fitted_trend(fit_adherence, adherence = TRUE)
```

We see that the data are consistent with non-adherent patients having both higher and lower average NYHA with the same VO~2~ peak. While it is possible that we could determine the sign of the difference with more data, the current data already allow us to rule out that there is a substantial difference. One way to quantify this is to look at the predictions for difference in mean transitional NYHA class across different VO~2~ peak levels, here a difference of 1 would mean an average increase of one transitional class (e.g., from "1-2" to "2" or from "2-3" to "3")

```{r}
prediction_mean_NYHA_diff <- function(fit, adherence = FALSE, VO2_peak_vals = c(10, 20, 30)) {
  prediction_df <- get_predictions(fit, adherence = adherence, VO2_peak_vals = VO2_peak_vals)
  prediction_wide <- prediction_df %>% pivot_wider(names_from = adherence_category, values_from = NYHA) %>%
    mutate(NYHA_diff = `Fully adherent` - `Nonadherent`)
  prediction_wide %>% group_by(VO2_peak) %>% summarise(`Mean Difference Adherent to Nonadherent` = round(mean(NYHA_diff), 2),
                                                      `95% CI` = paste0("[",round(quantile(NYHA_diff, probs = 0.025),2), " ; ", round(quantile(NYHA_diff, probs = 0.975), 2), "]")) %>%
    rename(`VO2 peak` = VO2_peak)
}

prediction_mean_NYHA_diff(fit_adherence, adherence = TRUE) %>% table_format()
```

While the point estimates are close to zero, the associated uncertainty says that a difference of more than half a transitional NYHA class (i.e. a quarter of the standard NYHA class) is not consistent with the data across various VO~2~ peak levels.

Further we can allow not only a constant shift, but also let the slope of the association vary, which we will call the "interaction" model.

```{r}
fit_adherence_int <- brm(NYHA_spiro ~ log(VO2_peak) * adherence_category, family = cumulative("logit"), data = data_nyha, 
                         iter = 6000, warmup = 2000, refresh = 1500,
                         file = here::here("stored_fits","nyha_adherence_int"), file_refit = "on_change") 
```

```{r, fig.cap = "Summary of the interaction model model. Each line is a posterior sample showing association between VO~2~ peak and average  NYHA. The thick light blue line shows expected output if NYHA based on VO~2~ peak exactly corresponded with  NYHA."}
plot_fitted_trend(fit_adherence_int, adherence = TRUE)
```

```{r}
prediction_mean_NYHA_diff(fit_adherence_int, adherence = TRUE) %>% table_format()
```


```{r}
# pred_int_for_10 <- posterior_predict(fit_adherence_int, newdata = data.frame(VO2_peak = 10, adherence_category = factor(c( "A - nonadherent" , "C - all"), ordered = TRUE, levels = levels(data_nyha$adherence_category) )))
# 
# prob_all_larger_nonadherent = mean(pred_int_for_10[,1] >= pred_int_for_10[,2] - 2)
```


Similarly to the constant shift model the results from the interaction model are not very conclusive: we cannot determine the sign of change and we can at best say that very large differences (more than 1 transitional NYHA class, i.e. half of NYHA class on average) are not consistent with the data. 

## Cohort differences?

Here we repeat some of the plots, but split by cohort:

```{r}
plot_scatter + facet_wrap(~cohort)
```

```{r}
data_nyha %>% 
  rowwise() %>%
  mutate(`NYHA vs. Weber status` = 
           case_when(grepl(Weber_spiro, as.character(NYHA_spiro)) ~ "Concordant",
                     Weber_spiro < as.integer(substr(NYHA_spiro, 1, 1)) ~ "Weber lower",
                     Weber_spiro > as.integer(substr(NYHA_spiro, 1, 1)) ~ "Weber higher",
                     TRUE ~ "Invalid")) %>%
  # filter(`NYHA status` == "Objective higher") %>%
  # select(Weber_spiro, NYHA_spiro)
  
  group_by(cohort, `NYHA vs. Weber status`) %>% tally() %>%
  table_format(caption = "Count of patients based on difference between  NYHA and Weber based on VO~2~ peak, split by cohort")
```


```{r}
plot_VO2_peak + facet_wrap(~cohort)
```

There doesn't appear to be any obvious difference.


```{r}
fit_boundaries_cohort_log <- brm(NYHA_spiro ~ log(VO2_peak) + factor(cohort), family = cumulative("logit"), data = data_nyha, 
                          iter = 6000, warmup = 2000,
                          file = here::here("stored_fits","boundaries_full_cohort_log"), file_refit = "on_change")
```

We can also try to include cohort in the statistical model. The results are inconclusive --- there is no evidence for a difference between the two cohorts, but unfortunately, we also cannot rule out a relatively big difference.

```{r}
summary(fit_boundaries_cohort_log)
```


## Main conclusions

```{r}
VO2_peak_25 <- data_nyha %>% ungroup() %>% filter(VO2_peak >= 25) %>% summarise(N = n(), NYHA_1 = sum(NYHA_spiro == "1"), NYHA_1_2 = sum(NYHA_spiro == "1-2"),   NYHA_2 = sum(NYHA_spiro == "2"))
```


- VO~2~ peak value from spiroergometry is an imperfect predictor of  NYHA score and vice versa. The agreement between spiroergometry and  NYHA is largest for high VO~2~ peak, but even among the `r VO2_peak_25$N` patients with VO~2~ peak > 25 ml/kg/min, only `r VO2_peak_25$NYHA_1` were assigned pure NYHA 1 while `r VO2_peak_25$NYHA_1_2` were assigned NYHA 1-2 and `r VO2_peak_25$NYHA_2` was assigned NYHA 2. The variability in  NYHA is even larger for low VO~2~ peak values.

-  NYHA 4 is almost unseen in the data - maybe patients with NYHA 4 were effectively excluded due to not being able to perform spiroergometry?

- If a better match between Weber derived from spiroergometry in this dataset and  NYHA was desired, the upper VO~2~ peak thresholds for Weber C and D would need to be moved down substantially and the threshold for Weber A would need to be moved up. 

- With the current data, we cannot say anything conclusive about the potential change of association between Weber  and  NYHA between adherent and non-adherent patient subgroups, although very large differences (an average of half a NYHA category or more in either direction) are not consistent with our data. The precision we can achieve is limited by the low number of non-adherent patients observed in the cohort. Results are very similar, if we also try to account for partial adherence (data not shown).

## Reproducibility

Full code to reproduce this report is part of this supplementary material in the file `nyha_full.Rmd`.

Packages used:

```{r}
sessionInfo()
```
